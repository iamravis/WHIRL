# LLM Service Environment Variables

# Model settings
LLM_MODEL=meta-llama/Llama-3.2-3B-Instruct
LLM_DEVICE=auto
LLM_QUANTIZATION=none

# ChromaDB settings
CHROMA_DB_PATH=../rag/chroma_db
DOCUMENT_CHUNKS_PATH=../rag/chunks/all_documents_chunks.json

# Service settings
ENABLE_QUERY_TRANSFORMATION=True
ENABLE_RERANKING=True

# Logging level
LOG_LEVEL=INFO

# Optional API keys for other models
# OPENAI_API_KEY=your-openai-key
# COHERE_API_KEY=your-cohere-key
